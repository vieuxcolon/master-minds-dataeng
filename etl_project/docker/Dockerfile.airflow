# Use the official Apache Airflow image as base
FROM apache/airflow:3.1.0

# Switch to root to install packages
USER root

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git \
    curl \
    wget \
    build-essential \
    default-libmysqlclient-dev \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements.txt (optional if you maintain it in the project)
COPY requirements.txt /tmp/requirements.txt

# Install Python dependencies needed for DAGs
RUN pip install --no-cache-dir --upgrade pip \
    && pip install --no-cache-dir -r /tmp/requirements.txt

# Set Airflow home and project directory (volumes mounted in docker-compose)
ENV AIRFLOW_HOME=/opt/airflow
WORKDIR ${AIRFLOW_HOME}

# Ensure Airflow user exists with proper UID
ARG AIRFLOW_UID=50000
RUN useradd -ms /bin/bash -u ${AIRFLOW_UID} airflow \
    && mkdir -p ${AIRFLOW_HOME}/dags ${AIRFLOW_HOME}/logs ${AIRFLOW_HOME}/plugins ${AIRFLOW_HOME}/data \
    && chown -R airflow: ${AIRFLOW_HOME}

# Switch back to airflow user
USER airflow

# Expose ports used by Airflow
EXPOSE 8080 8793 5555

# Entrypoint is inherited from base Airflow image

